{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8244881,"sourceType":"datasetVersion","datasetId":4891392},{"sourceId":8245013,"sourceType":"datasetVersion","datasetId":4891490}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n        \n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-02T11:20:08.932126Z","iopub.execute_input":"2024-05-02T11:20:08.932538Z","iopub.status.idle":"2024-05-02T11:20:08.947958Z","shell.execute_reply.started":"2024-05-02T11:20:08.932507Z","shell.execute_reply":"2024-05-02T11:20:08.946968Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"/kaggle/input/textandintents/is_train.csv\n/kaggle/input/testing-and-validation-dataset/is_val.csv\n/kaggle/input/testing-and-validation-dataset/is_test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\ntrain_df = pd.read_csv(\"/kaggle/input/textandintents/is_train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/testing-and-validation-dataset/is_test.csv\")\nval_df = pd.read_csv(\"/kaggle/input/testing-and-validation-dataset/is_val.csv\")\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-02T11:20:08.949986Z","iopub.execute_input":"2024-05-02T11:20:08.950719Z","iopub.status.idle":"2024-05-02T11:20:09.032289Z","shell.execute_reply.started":"2024-05-02T11:20:08.950686Z","shell.execute_reply":"2024-05-02T11:20:09.031354Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                                   0          1\n0  what expression would i use to say i love you ...  translate\n1  can you tell me how to say 'i do not speak muc...  translate\n2  what is the equivalent of, 'life is good' in f...  translate\n3  tell me how to say, 'it is a beautiful morning...  translate\n4  if i were mongolian, how would i say that i am...  translate","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>what expression would i use to say i love you ...</td>\n      <td>translate</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>can you tell me how to say 'i do not speak muc...</td>\n      <td>translate</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>what is the equivalent of, 'life is good' in f...</td>\n      <td>translate</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>tell me how to say, 'it is a beautiful morning...</td>\n      <td>translate</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>if i were mongolian, how would i say that i am...</td>\n      <td>translate</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_df.columns = [\"text\",\"intent\"]\ntest_df.columns = [\"text\",\"intent\"]\nval_df.columns = [\"text\",\"intent\"]","metadata":{"execution":{"iopub.status.busy":"2024-05-02T11:20:09.033485Z","iopub.execute_input":"2024-05-02T11:20:09.033769Z","iopub.status.idle":"2024-05-02T11:20:09.039042Z","shell.execute_reply.started":"2024-05-02T11:20:09.033745Z","shell.execute_reply":"2024-05-02T11:20:09.037892Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-02T11:20:09.040316Z","iopub.execute_input":"2024-05-02T11:20:09.040597Z","iopub.status.idle":"2024-05-02T11:20:09.056998Z","shell.execute_reply.started":"2024-05-02T11:20:09.040573Z","shell.execute_reply":"2024-05-02T11:20:09.055832Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                                text     intent\n0  what expression would i use to say i love you ...  translate\n1  can you tell me how to say 'i do not speak muc...  translate\n2  what is the equivalent of, 'life is good' in f...  translate\n3  tell me how to say, 'it is a beautiful morning...  translate\n4  if i were mongolian, how would i say that i am...  translate","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>intent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>what expression would i use to say i love you ...</td>\n      <td>translate</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>can you tell me how to say 'i do not speak muc...</td>\n      <td>translate</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>what is the equivalent of, 'life is good' in f...</td>\n      <td>translate</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>tell me how to say, 'it is a beautiful morning...</td>\n      <td>translate</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>if i were mongolian, how would i say that i am...</td>\n      <td>translate</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\n\n# Shuffle the training DataFrame\ntrain_df_shuffled = train_df.sample(frac=1,random_state = 42).reset_index(drop=True)\n\n\n# Tokenize text data\ntokenizer = tf.keras.preprocessing.text.Tokenizer()\ntokenizer.fit_on_texts(train_df_shuffled['text'])\n\n# Tokenize training text data\ntrain_sequences = tokenizer.texts_to_sequences(train_df_shuffled['text'])\n\n# Tokenize validation text data\nval_sequences = tokenizer.texts_to_sequences(val_df['text'])\n\n# Tokenize testing text data\ntest_sequences = tokenizer.texts_to_sequences(test_df['text'])\n\n# Pad sequences to ensure uniform length\nmax_length = max(len(seq) for seq in train_sequences + val_sequences + test_sequences)\ntrain_padded_sequences = tf.keras.preprocessing.sequence.pad_sequences(train_sequences, maxlen=max_length, padding='post')\nval_padded_sequences = tf.keras.preprocessing.sequence.pad_sequences(val_sequences, maxlen=max_length, padding='post')\ntest_padded_sequences = tf.keras.preprocessing.sequence.pad_sequences(test_sequences, maxlen=max_length, padding='post')\n\n# Convert intents to unique integer labels\nintent_label_mapping = {label: idx for idx, label in enumerate(train_df_shuffled['intent'].unique())}\ntrain_df_shuffled['intent_labels'] = train_df_shuffled['intent'].map(intent_label_mapping)\nval_df['intent_labels'] = val_df['intent'].map(intent_label_mapping)\ntest_df['intent_labels'] = test_df['intent'].map(intent_label_mapping)\n\n# Convert integer labels to one-hot encoding\nnum_intents = len(intent_label_mapping)\ntrain_intent_labels = tf.keras.utils.to_categorical(train_df_shuffled['intent_labels'], num_classes=num_intents)\nval_intent_labels = tf.keras.utils.to_categorical(val_df['intent_labels'], num_classes=num_intents)\ntest_intent_labels = tf.keras.utils.to_categorical(test_df['intent_labels'], num_classes=num_intents)\n\n# Define RNN model with additional layers and increased units in the embedding layer\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=200, input_length=max_length),\n    tf.keras.layers.LSTM(128, return_sequences=True),  # Adding another LSTM layer with return_sequences=True\n    tf.keras.layers.LSTM(64),  # Adding another LSTM layer\n    tf.keras.layers.Dense(128, activation='relu'),  # Adding a Dense hidden layer\n    tf.keras.layers.Dense(num_intents, activation='softmax')  # Output layer with softmax activation\n])\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Train the model with validation data\nmodel.fit(train_padded_sequences, train_intent_labels, epochs=50, batch_size=32, validation_data=(val_padded_sequences, val_intent_labels))\n\n# Evaluate the model on the test data\nloss, accuracy = model.evaluate(test_padded_sequences, test_intent_labels)\nprint(\"Test Accuracy:\", accuracy)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-02T11:20:09.059431Z","iopub.execute_input":"2024-05-02T11:20:09.059963Z","iopub.status.idle":"2024-05-02T11:23:27.679647Z","shell.execute_reply.started":"2024-05-02T11:20:09.059927Z","shell.execute_reply":"2024-05-02T11:23:27.678826Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:86: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.0127 - loss: 4.8787 - val_accuracy: 0.0653 - val_loss: 3.8355\nEpoch 2/50\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.1020 - loss: 3.3932 - val_accuracy: 0.2040 - val_loss: 2.8975\nEpoch 3/50\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.2835 - loss: 2.3255 - val_accuracy: 0.4167 - val_loss: 2.1040\nEpoch 4/50\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.5842 - loss: 1.3629 - val_accuracy: 0.6363 - val_loss: 1.5610\nEpoch 5/50\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7728 - loss: 0.7679 - val_accuracy: 0.7137 - val_loss: 1.3577\nEpoch 6/50\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8711 - loss: 0.4507 - val_accuracy: 0.7310 - val_loss: 1.3657\nEpoch 7/50\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9086 - loss: 0.3217 - val_accuracy: 0.7663 - val_loss: 1.2684\nEpoch 8/50\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9328 - loss: 0.2309 - val_accuracy: 0.7753 - val_loss: 1.2865\nEpoch 9/50\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.1788 - val_accuracy: 0.7773 - val_loss: 1.2781\nEpoch 10/50\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9613 - loss: 0.1412 - val_accuracy: 0.7800 - val_loss: 1.3324\nEpoch 11/50\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9646 - loss: 0.1210 - val_accuracy: 0.7857 - val_loss: 1.3467\nEpoch 12/50\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9709 - loss: 0.1060 - val_accuracy: 0.7990 - val_loss: 1.3854\nEpoch 13/50\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9773 - loss: 0.0791 - val_accuracy: 0.7857 - val_loss: 1.4622\nEpoch 14/50\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9731 - loss: 0.1013 - val_accuracy: 0.7983 - val_loss: 1.4024\nEpoch 15/50\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9865 - loss: 0.0528 - val_accuracy: 0.8093 - val_loss: 1.3619\nEpoch 16/50\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9846 - loss: 0.0572 - val_accuracy: 0.8070 - val_loss: 1.4047\nEpoch 17/50\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9812 - loss: 0.0635 - val_accuracy: 0.8137 - val_loss: 1.4390\nEpoch 18/50\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9906 - loss: 0.0362 - val_accuracy: 0.8077 - val_loss: 1.4957\nEpoch 19/50\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9863 - loss: 0.0485 - val_accuracy: 0.8080 - val_loss: 1.5540\nEpoch 20/50\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9867 - loss: 0.0476 - val_accuracy: 0.8210 - val_loss: 1.5126\nEpoch 21/50\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9929 - loss: 0.0282 - val_accuracy: 0.8273 - val_loss: 1.4197\nEpoch 22/50\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9941 - loss: 0.0234 - val_accuracy: 0.8200 - val_loss: 1.5235\nEpoch 23/50\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9936 - loss: 0.0252 - val_accuracy: 0.8047 - val_loss: 1.5868\nEpoch 24/50\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9840 - loss: 0.0507 - val_accuracy: 0.8273 - val_loss: 1.4814\nEpoch 25/50\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9916 - loss: 0.0289 - val_accuracy: 0.8230 - val_loss: 1.5348\nEpoch 26/50\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9912 - loss: 0.0284 - val_accuracy: 0.8257 - val_loss: 1.5222\nEpoch 27/50\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9930 - loss: 0.0214 - val_accuracy: 0.8230 - val_loss: 1.5146\nEpoch 28/50\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9941 - loss: 0.0209 - val_accuracy: 0.8247 - val_loss: 1.5359\nEpoch 29/50\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9922 - loss: 0.0298 - val_accuracy: 0.8363 - val_loss: 1.5033\nEpoch 30/50\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9957 - loss: 0.0150 - val_accuracy: 0.8320 - val_loss: 1.5182\nEpoch 31/50\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9979 - loss: 0.0080 - val_accuracy: 0.8367 - val_loss: 1.5640\nEpoch 32/50\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9988 - loss: 0.0055 - val_accuracy: 0.8390 - val_loss: 1.5603\nEpoch 33/50\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9962 - loss: 0.0153 - val_accuracy: 0.8153 - val_loss: 1.6284\nEpoch 34/50\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9856 - loss: 0.0521 - val_accuracy: 0.8223 - val_loss: 1.6066\nEpoch 35/50\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9941 - loss: 0.0223 - val_accuracy: 0.8327 - val_loss: 1.6186\nEpoch 36/50\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9966 - loss: 0.0128 - val_accuracy: 0.8303 - val_loss: 1.6618\nEpoch 37/50\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9967 - loss: 0.0108 - val_accuracy: 0.8327 - val_loss: 1.6062\nEpoch 38/50\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9968 - loss: 0.0114 - val_accuracy: 0.8313 - val_loss: 1.6269\nEpoch 39/50\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9948 - loss: 0.0158 - val_accuracy: 0.8223 - val_loss: 1.6545\nEpoch 40/50\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9946 - loss: 0.0205 - val_accuracy: 0.8410 - val_loss: 1.5877\nEpoch 41/50\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9979 - loss: 0.0058 - val_accuracy: 0.8380 - val_loss: 1.6370\nEpoch 42/50\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9954 - loss: 0.0158 - val_accuracy: 0.8390 - val_loss: 1.6860\nEpoch 43/50\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9929 - loss: 0.0273 - val_accuracy: 0.8340 - val_loss: 1.6533\nEpoch 44/50\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9943 - loss: 0.0174 - val_accuracy: 0.8330 - val_loss: 1.6574\nEpoch 45/50\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9971 - loss: 0.0108 - val_accuracy: 0.8330 - val_loss: 1.6291\nEpoch 46/50\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9969 - loss: 0.0078 - val_accuracy: 0.8377 - val_loss: 1.6846\nEpoch 47/50\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9985 - loss: 0.0070 - val_accuracy: 0.8387 - val_loss: 1.6386\nEpoch 48/50\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9991 - loss: 0.0037 - val_accuracy: 0.8433 - val_loss: 1.6193\nEpoch 49/50\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9976 - loss: 0.0088 - val_accuracy: 0.8293 - val_loss: 1.7541\nEpoch 50/50\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9964 - loss: 0.0149 - val_accuracy: 0.8267 - val_loss: 1.8088\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8315 - loss: 1.5661\nTest Accuracy: 0.8342221975326538\n","output_type":"stream"}]},{"cell_type":"code","source":"# lstm_model = tf.keras.models.load_model('Intent_DetectV1.h5')\n# Tokenize the input sentence\ninput_sentence = \"where is my flight\"\ninput_sequence = tokenizer.texts_to_sequences([input_sentence])\n\n# Pad the tokenized sequence\ninput_padded_sequence = tf.keras.preprocessing.sequence.pad_sequences(input_sequence, maxlen=max_length, padding='post')\n\n# Predict intent label\npredicted_label = model.predict(input_padded_sequence)[0]\n\n# Map predicted label back to original intent\npredicted_intent = list(intent_label_mapping.keys())[np.argmax(predicted_label)]\n\nprint(\"Predicted Intent:\", predicted_intent)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-02T11:23:27.680888Z","iopub.execute_input":"2024-05-02T11:23:27.681691Z","iopub.status.idle":"2024-05-02T11:23:27.932948Z","shell.execute_reply.started":"2024-05-02T11:23:27.681656Z","shell.execute_reply":"2024-05-02T11:23:27.932019Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step\nPredicted Intent: flight_status\n","output_type":"stream"}]},{"cell_type":"code","source":"model.save(\"Intent_DetectV3.keras\")","metadata":{"execution":{"iopub.status.busy":"2024-05-02T11:23:27.934111Z","iopub.execute_input":"2024-05-02T11:23:27.934412Z","iopub.status.idle":"2024-05-02T11:23:28.041892Z","shell.execute_reply.started":"2024-05-02T11:23:27.934387Z","shell.execute_reply":"2024-05-02T11:23:28.041133Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Next Step is to develop a NER Model ","metadata":{"execution":{"iopub.status.busy":"2024-05-02T11:23:28.043046Z","iopub.execute_input":"2024-05-02T11:23:28.043388Z","iopub.status.idle":"2024-05-02T11:23:28.047964Z","shell.execute_reply.started":"2024-05-02T11:23:28.043357Z","shell.execute_reply":"2024-05-02T11:23:28.047032Z"},"trusted":true},"execution_count":11,"outputs":[]}]}